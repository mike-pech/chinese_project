{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3a1d5d-6845-4882-81d1-30c74c720a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1eb05f-1110-4b67-ac7e-4a1e1b6e7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_common_text(texts):\n",
    "    if not texts:\n",
    "        return \"\"\n",
    "    # при условии что все тексты одинаковой длины, set length to one of the sample's text length\n",
    "    text_length = len(texts[0])\n",
    "    # пустой стринг для записи итогового слова\n",
    "    average_word = \"\"\n",
    "\n",
    "    # проходимся по каждой буковке\n",
    "    for i in range(text_length):\n",
    "        # изымаем буковку из каждого слова\n",
    "        characters_at_position = [text[i] for text in texts]\n",
    "        # считаем самую повторяющуюся букву\n",
    "        most_common_letter, _ = Counter(characters_at_position).most_common(1)[0]\n",
    "        # собираем полученные частые буковки в одно слово\n",
    "        average_word += most_common_letter\n",
    "    return average_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3b4bdf-a52b-40f4-906f-bc04219633a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вег\n"
     ]
    }
   ],
   "source": [
    "texts = [\"виг\", \"век\", \"пег\"]\n",
    "# texts = [\"бие\", \"пиех\", \"бые\", \"бе\"]\n",
    "result = calculate_common_text(texts)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7a4f4",
   "metadata": {},
   "source": [
    "Версия для слов разной длины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7905de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_common_text(texts: list) -> str:\n",
    "    if not texts:\n",
    "        return \"\"\n",
    "\n",
    "    tokenized = [entry.split() for entry in texts]\n",
    "    tokenized = [[token[i] for token in tokenized] for i in range(len(tokenized[0]))]\n",
    "    # print(tokenized)\n",
    "\n",
    "    average_text = []\n",
    "\n",
    "    for token in tokenized:\n",
    "        num = round(sum(len(word) for word in token) / len(token))\n",
    "\n",
    "        average_token = \"\"\n",
    "\n",
    "        for i in range(num):\n",
    "            characters_at_position = [letter[i] if i < len(letter) else \"\" for letter in token]\n",
    "            # print(characters_at_position)\n",
    "            # print(i)\n",
    "        \n",
    "            if not characters_at_position[i]:\n",
    "                characters_at_position[i] = Counter(characters_at_position).most_common(2)[1][0]\n",
    "\n",
    "            most_common_letter, _ = Counter(characters_at_position).most_common(1)[0]\n",
    "            average_token += most_common_letter\n",
    "        \n",
    "        average_text.append(average_token)\n",
    "\n",
    "    return \" \".join(average_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d8ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS:\n",
      "\n",
      "вег\n",
      "бие\n",
      "ган\n",
      "бие жень\n",
      "хан тзы\n",
      "ченг шу\n",
      "суан тиан ку ла\n"
     ]
    }
   ],
   "source": [
    "TEST_TEXTS = [[\"виг\", \"век\", \"пег\"],                            # виг\n",
    "              [\"бие\", \"пиех\", \"бые\", \"бе\"],                     # бие\n",
    "              [\"ган\", \"кан\", \"ган\", \"гань\"],                    # ган\n",
    "              [\"бие рен\", \"пиех жэнь\", \"бые жэнь\", \"бе жень\"],  # бие жэ(е?)нь\n",
    "              [\"хан зи\", \"хан тзу\", \"ханн тзых\", \"хань цзы\"],   # хан тзы\n",
    "              [\"женг шу\", \"ченг шу\", \"йенк шу\", \"чжэн шу\"],     # ченг шу\n",
    "              [\"суан тиан ку ла\", \"суан тиен ку ла\",\"суан тыан куу лах\", \"суань тянь ку ла\"]]\n",
    "                                                                # суан тиан ку ла\n",
    "print(\"TESTS:\\n\")\n",
    "for sample in TEST_TEXTS:\n",
    "    print(calculate_common_text(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a1137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
